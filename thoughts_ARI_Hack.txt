Thoughts:

There are a variety of image file types, some of them require special software and lib to read;
the raw jpg images were taken from different height, angel, and some photos has partial or non houses presented;
the orthomosaic images have done the image rectification, correction, so is good to measure distance, a question is
would orthomosaic image be available in testing data as well? can it be used as one of the training data to build a model?
we have 3d mesh(wavefront called, has .obj and .mtl files), point cloud, dsm(tiff) which I guess are all for 3d? how we can read those files and how to use them? 
what differences and how they can be used together with orthomosaic? how image coordiatnes are interprated?

pyglet and pywavefront were installed to read wavefront objects:
install pyglet: pip install pyglet
install pywavefront: download https://github.com/greenmoss/PyWavefront, goto the top directoy
, python setup.py install and pip install PyWavefront, see https://github.com/greenmoss/PyWavefront,
then test using import pywavefront

pcl installation:
conda install -c ccordoba12 python-pcl=0.2
following https://anaconda.org/ccordoba12/python-pcl

PIL can be used to read tiff images

07/30/2016
Tried to use pywavefront to read .obj data in 3d mesh folder, when running the script in jupyter notebook,
gets error cant find file in the path, tried to use os.chdir and sys.path.append, none of them work, and then
I tried to run test.py in the folder, it says found texture coordiantes, but no normals;
Tries to run the pyglet_demo.py in pywavefront-master/example folder, it ran successfully using uv_sphere.obj,
when changed to use test.obj cced from 3d_mesh,got same error not found the normals

07/31/2016
pics were taken at 100 feet as video says mostly, each pic's taken coordiante and altitude
was taken, but not sure the units; UVA will follow a pre-programmed 
Thoughts on approach the project:
1. way to filter in only roof images(33 -34 were used out of 80 for pix4d)
2. way to find the right components to rebuild the house geometrically
3. identify in each picture, if there is a geometric component exists, if yes, 
find a way to crop it, and calculate the cropped part's area
4. add up the geometric component's area

gotchas: find the right house if multiple houses exist;
         same component may get different areas estimated;
         slopes, ridges estimation?
         maybe a good way to count the number of bricks? and extrapolate to roof area
         that would solve the slope calculation as well
         
Immediate to-dos: gets software ready to read all the files, point cloud, 3d- mesh
				  find a big portion of the house, and find a way to crop a geometric component
				  find a way to extract shape and compare if it is the same shape

08/03/2016
Thoughts:
use the tiff, xyz, dsm data
raster data not efficient
extract polygons and convert into vector data to calculate area
maybe covert to shape files? which needs at least one attribute field

08/05/2016
shape file is converted and polygons saved, however:
need to find a way to visualize the shapes, tune the filter, and get the geo reference info
probably need to understand more the shape file and how to query the attribute, field and do some calculation from there

08/06/2016
pip install pyshp -- to get shapefile module
pip install descartes -- to get descartes module

link to print shape file: http://gis.stackexchange.com/questions/131716/plot-shapefile-with-matplotlib
http://gis.stackexchange.com/questions/93136/how-to-plot-geo-data-using-matplotlib-python/93201#93201

python create_shapfiles.py -d '../data/dsm' -e tif doesn't work

need to understand how to extract contour based on color using cv2, cv2 also
has function to computer area of contour:
http://docs.opencv.org/trunk/dd/d49/tutorial_py_contour_features.html#gsc.tab=0
also need to print and show pic in a smaller size

optimize performance:
http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_core/py_optimization/py_optimization.html#optimization-techniques

08/08/2016
from kick-off meeting:
most flights taken from 100 to 400 feet height 
allied drones AT28, DJI Inspire
http://www.dji.com/product/inspire-1-pro-and-raw
initial focus: 2 story and steep homes in hail prone states

RMSE is the accuracy metric
test file to submit:
house name(50), square feet, time to run


Delauney in scipy , convexHull has a way to compute 3d

the current problem:
contour only works for grayscale
1. the default imread(img,0), put the house shape blurred inside the lawn
once grayscaled, then need to find a good thresholding to whiten the house(set the pixel to 0), while
the rest to 1(black) using some kind of color based(red,orange above to 0)
then apply either the canny edge, or filtering or default find contour which will
all produce polygons
2. find good color limits to seperate the house, threshold there, and then 

Gary's approach: get the image to 0 and 1 binary,and then apply a median filter there, by eyes determine
the window size, didn't use the bool cut

thresholding:http://docs.opencv.org/trunk/d7/d4d/tutorial_py_thresholding.html#gsc.tab=0

PROGRESS:
get a rough estimate by counting the sum of largest contours using manual set threshold
need to find a way to get the several largest contours using ranking system
to improve efficiency, need to scale down the images and then later times up the scale factor
need to find a way to calculate angel and plot individual contour

need find a way to do convexhull and plot individual contour and fillpoly


08/09/2016
project_dsm, rasterBand1 has height info, and it does not have other bands
while color_relief has 4 bands, rgb and alpha info, no height;
the first mask is using opencv rbg mask; now need to make a mask using height info that
can be read from gdal

08/10/2016
the rgb mask breaks some house apart from the middle, need to find better rgb upper threshold
threshold removed and that get height mask better performed; however some adjacent trees are
accounted into, and need to erode the away

next step:
pull the not working well samples
tune one by one to get the best: height mask, threshold, and 
and also found a way to get the labels in and calculate rmse for each sample and samples totall


discussion with Jing:
1. Only use height mask from project_dsm.tif, need to find a good threshold limits:
     1.1 Convoluted Sampling from the central area of the tif, get a height distribution or
   		directly start from the central, get the top say 30% height, using that as height threshold as
    	self adaptive threshold method, once we find the threshold then use slight window
     1.2 one common threshold limits, to run through all samples, and then 
     change threshold based on the predicted area falling into too large(>1,0000) or too small( < 500)
     
Get one script, read opencv version and decide which findcontour and directory to use, depending
on edgenode or local mac -- done!
